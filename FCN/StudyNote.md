# FCN学习笔记
****
## 一、模型简介
全卷积网络（Fully Convolutional Networks，FCN）是Jonathan Long等人于2015年在Fully Convolutional Networks for Seman  tic Segmentation一文中提出的用于图像语义分割的一种框架，是深度学习用于语义分割领域的开山之作。FCN将传统CNN后面的全连接层换成了卷积层，这样网络的输出将是热力图而非类别；同时，为解决卷积和池化导致图像尺寸的变小，使用上采样方式对图像尺寸进行恢复。

>论文链接: https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf
****
## 二、模型特点
1. 不含全连接层的全卷积网络，可适应任意尺寸输入。
2. 反卷积层增大图像尺寸，输出精细结果。
3. 结合不同深度层结果的跳级结构，确保鲁棒性和精确性。
****
## 三、网络结构
![FCN 网络结构图](https://img-blog.csdnimg.cn/20190612105638654.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0dV9zaGFuZ2h1aQ==,size_16,color_FFFFFF,t_70)


**流程理解**
- FCN网络结构主要分为两个部分：全卷积部分和反卷积部分。
- 其中全卷积部分为一些经典的CNN网络（如VGG，ResNet等），用于提取特征。
- 反卷积部分则是通过上采样得到原尺寸的语义分割图像。
- FCN的输入可以为任意尺寸的彩色图像，输出与输入尺寸相同，通道数为n（目标类别数）+1（背景）。

**全卷积（下采样）**
在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个不同类别的概率。FCN将这3层表示为卷积层，卷积核的大小 (通道数，宽，高) 分别为 (4096,1,1)、(4096,1,1)、(1000,1,1)。看上去数字上并没有什么差别，但是卷积跟全连接是不一样的概念和计算过程，使用的是之前CNN已经训练好的权值和偏置，但是不一样的在于权值和偏置是有自己的范围，属于自己的一个卷积核。

**反卷积（上采样）**
反卷积(deconvolutional)运算的参数和CNN的参数一样是在训练FCN模型的过程中通过bp算法学习得到。反卷积层也是卷积层，不关心input大小，滑窗卷积后输出output。deconv并不是真正的deconvolution（卷积的逆变换），最近比较公认的叫法应该是transposed convolution，deconv的前向传播就是conv的反向传播。

反卷积参数: 利用卷积过程filter的转置（先水平翻转，再竖直方向上翻转filter）作为计算卷积前的特征图。

**跳级结构**
对CNN的结果做处理，得到了dense prediction，而作者在试验中发现，得到的分割结果比较粗糙，所以考虑加入更多前层的细节信息，也就是把倒数第几层的输出和最后的输出做一个fusion，就是对应元素相加。

****
## 四、模型优缺点
- **优点**：与传统用CNN进行图像分割的方法相比，FCN有两大明显的优点：一是可以接受任意大小的输入图像，而不用要求所有的训练图像和测试图像具有同样的尺寸。二是更加高效，因为避免了由于使用像素块而带来的重复存储和计算卷积的问题。


- **缺点**：同时FCN的缺点也比较明显：一是得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感。二是对各个像素进行分类，没有充分考虑像素与像素之间的关系，忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。

